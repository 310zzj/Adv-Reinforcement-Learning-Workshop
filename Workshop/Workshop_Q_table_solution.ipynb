
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning using tables\n",
    "##### Authors: Eirik Fagtun Kj√¶rnli and Fabian Dietrichson [Accenture]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome \n",
    "Welcome to this workshop!\n",
    "\n",
    "The workshop is structured such that for each cell, you will write your own code and the code will then be asserted in the next cell. The assertion cell is marked \"# Do not edit - Assertion cell #\". <br>\n",
    "The code should be written between \"Write code below\" and \"Write code above\". If your code does not pass the assertion, you will have to rewrite it before continuing.\n",
    "\n",
    "### Task:\n",
    "Implement the method multiply_input_by_2\n",
    "- The code should take the input variabel \"input_variabel\", and multiply it by 2\n",
    "- The answer should be stored in the variabel \"result\"\n",
    "- When the method is implemented, run the cell.\n",
    "\n",
    "Hotkey to run a cell: CTRL + ENTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_input_by_2(input_variabel):\n",
    "\n",
    "    \"Write code below\" \n",
    "    result = input_variabel * 2\n",
    "    \n",
    "    \"Write code above\" \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not edit - Assertion cell #\n",
    "assert(multiply_input_by_2(10) == 20), \"Your method did not multiple the input by 2\"\n",
    "print(\"Great, you correctly implemented the method!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages\n",
    "To implement the native Q-learning algorithm and use it in an environment, we just need two additional packages.\n",
    "\n",
    "_Numpy_\n",
    "- Numpy adds support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays. We could do this workshop using native Python arrays and built-in methods, however using Numpy simplifies the process. \n",
    "- To call the methods in the package, we use the \"as np\" command. Such that, to create a numpy table with 2 rows and 2 columns where all the cells are zero, you can simply write np.seros(2,2).\n",
    "\n",
    "_OpenAI Gym_\n",
    "- The Gym library is a collection of demo problems an associated environment, that you can use to work out your reinforcement learning algorithms. These range from simple text problems, to complex physical problems, to Atari video games. OpenAI Gym is therefore by many the preferred framework to learn and test Reinforcement learning algorithms.\"\n",
    "\n",
    "\n",
    "### Task:\n",
    "To import the necessary packages, simply run the cell below, and then run the assertion cell to verify that they have been imported correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not edit - Assertion cell #\n",
    "try:\n",
    "    assert(gym)\n",
    "    print(\"Great, the packages were imported correctly!\")\n",
    "except:\n",
    "    print(\"You did not run the cell above, do this before you continue!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Introduction\n",
    "\n",
    "The environment we are going to use is a simple grid world, where the agent is controlling a taxi. The environment was introduced in [Dietterich2000] to illustrate some issues in hierarchical reinforcement learning. There are 4 locations (labeled by different letters) and your job is to pick up the passenger at one location and drop the passenger off in another. You can read more about the environment [here](https://gym.openai.com/envs/Taxi-v2/).\n",
    "\n",
    "### Task:\n",
    "Create the environment variable containing all necessary methods to run the Taxi-v3 game. <br>\n",
    "\n",
    "_Tip: Just run the cell below_"
   ]
  },